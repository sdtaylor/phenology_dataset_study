%% Submissions for peer-review must enable line-numbering 
%% using the lineno option in the \documentclass command.
%%
%% Preprints and camera-ready submissions do not need 
%% line numbers, and should have this option removed.
%%
%% Please note that the line numbering option requires
%% version 1.1 or newer of the wlpeerj.cls file, and
%% the corresponding author info requires v1.2

\documentclass[fleqn,10pt,lineno]{wlpeerj} % for journal submissions
% \documentclass[fleqn,10pt]{wlpeerj} % for preprint submissions

\title{Comparison of large-scale citizen science data and long-term study data for phenology modeling}

\author[1]{Shawn D. Taylor}
\author[1]{Joan M. Meiners}
\author[2]{Kristina Riemer}
\author[3]{Michael C. Orr}
\author[2,4]{Ethan P. White}

\affil[1]{School of Natural Resources and Environment, University of Florida Gainesville, FL, United States}
\affil[2]{Department of Wildlife Ecology and Conservation, University of Florida, Gainesville, FL, United States}
\affil[3]{Key Laboratory of Zoological Systematics and Evolution, Institute of Zoology, Chinese Academy of Sciences, Beijing 100101, P.R. China}
\affil[4]{Informatics Institute, University of Florida, Gainesville, FL, United States}
\corrauthor[1]{Shawn D. Taylor}{shawntaylor@weecology.org}

% \keywords{Keyword1, Keyword2, Keyword3}

\begin{abstract}
\end{abstract}

\begin{document}

\flushbottom
\maketitle
\thispagestyle{empty}

\section*{Introduction}

Plant phenology, the timing of biological events such as flowering, plays an important role in many fields of ecological research extending from local to global scales \citep{cleland2007, richardson2013, tang2016}. At large scales, variation in the timing of spring leaf out and fall senescence influence the carbon budget of earth system models, which has implications for correctly accounting for biosphere-atmosphere feedbacks in long-term climate forecasts \citep{richardson2012}. At local scales, species-specific responses to temperature and precipitation can alter flower communities \citep{diez2012, caradonna2014, theobald2017} and affect the abundance and richness of both pollinators \citep{ogilvie2017a, ogilvie2017b} and higher trophic levels \citep{tylianakis2008}. Robust cross-scale plant phenology models are needed for understanding the processes governing these key timings of biological events and forecasting the impacts of changes in these timings in response to environmental change.  

Many plant phenology studies use intensively collected datasets collected at a single location over a long time-period by a single research group \citep{cook2012, wolkovich2012, iler2013, roberts2015}. These datasets have regular sampling and large numbers of samples over extensive periods of time. As a result they represent the biological and climatic variability at that site extremely well. However, it is common for phenology models built with observations from a single site to not transfer well to other sites \citep{garcia-mozo2008, xu2013, olsson2014, basler2016}. This lack of transferability can be driven by plasticity in phenology requirements, local adaptation, microclimates, and differences in plant age and population density \citep{kramer1995, diez2012}. In addition, data from a single location may not be adequate for larger scale phenology modelling due to limited species pools. Therefore it has been suggested that accurately understanding and forecasting phenology at larger scales will require models that account for the full range of variation across a species range \citep{richardson2013, chuine2017}.This will necessitate the use of data sources beyond traditional single site studies.

Data from citizen science projects is becoming increasingly important for ecological research \citep{kelling2009, dickinson2010, tulloch2013}. Because this data is often collected by large numbers of volunteers it is possible to gather data at much larger scales than with individual research teams. A relatively new citizen science project, The National Phenology Network (NPN) collects phenology observations from volunteers throughout North America and makes the data openly available \citep{schwartz2012a}. Data from this project has already been used to study continental-scale variation in oak phenology \citep{gerst2017}, develop large-scale community phenology models \citep{melaas2016}, and forecast long-term phenology trends \citep{jeong2013}. Large scale datasets from China and Europe have already contributed considerably to phenological research \citep{xu2013, olsson2014, basler2016, zhang2017}, and the NPN dataset has the potential to meet these needs for North American plant species and communities. However, the features that allow citizen science projects to collect data at large-scales can also introduce sources of error including spatial biases toward cities and easily accessible areas and variation in sampling effort and observer skill \citep{dickinson2010}. With hundreds of participants across North America, the potential for variation among observers for species identification and dating phenological events is high. While volunteers have been shown to be accurate at distinguishing different phenophases \citep{fuccillo2015}, observations are sometimes made sporadically within seasons, across years, and among locations. This means that the quality of the data at a specific site will typically be lower than for intensive long-term studies.

In order to accurately model and forecast phenology, it is important to understand how the strengths and weaknesses of intensive local studies and large scale citizen science projects influence both our inferences about biological processes and our ability to predict future phenology events. Here, we fit a suite of plant phenology models for the budburst and first flowering phenophases of 24 plant species to data from both the NPN and a set of intensive long-term studies. We compare the resulting models based on both inference about models and parameters and predictions for unobserved events. We use this comparison to assess the best methods for both local and large scale phenology modeling and to point the way forward for integrating large scale and local scale data to obtain the best possible models across scales.

\section*{Methods}

\subsection*{Datasets}

The National Phenology Network protocol uses status-based monitoring, where observers answer yes, no, or unsure when asked if an individual plant has a specific phenophase present \citep{denny2014}. Phenophases refer to specific phases in the annual cycle of a plant, such as the presence of emerging leaves, flowers, fruit, or senescing leaves. We downloaded all NPN observations from 2009, when collections began, to 2016 for the phenophases Breaking Leaf Buds, Breaking Needle Buds, Emerging Needles, and Open Flowers. The first three phenophases apply to the leaf out phase for deciduous broadleafs, evergreen conifers, and pines, respectively. The Open Flowers phenophase indicates fully open flowers and applies to all angiosperms. Hereafter we will refer to these as either Flowers for the Open Flower phenophase, or Budburst for all other phenophases. 

We used moderately strict subsetting of NPN phenology observations as outlined in \cite{crimmins2017}. First, "yes" observations for individual plants were only kept if they were preceded by a "no" observation within 30 days. Observations for Budburst past day of year (DOY) 172 and for Flowers past DOY 213 were dropped to minimize any influence from outliers. Finally, only species that had greater than 30 total observations were kept. \cite{crimmins2017} only kept observations that were preceded by a "no" within 15 days, and also grouped multiple individuals at single sites to a single observation. We used 30 days to allow for a greater number of species to be compared. We did not group together multiple individuals at a single site to better incorporate intra-site variability. In addition to these steps we also inferred the date of each phenophase as the midpoint between each "yes" observation and the preceding "no" observation. 

To represent long-term intensive phenology studies we used four datasets from North America (Table 1), representing three major ecosystem types and 24 species. All four long-term studies are located in the U.S.A and are part of the Long Term Ecological Research network. The Harvard Forest and Hubbard Brook Long Term Experimental Forest are located in the northeastern U.S.A. and are dominated by deciduous broadleaf species. The H.J. Andrews Experimental Forest is a coniferous forest in the coastal range of the western U.S.A. The Jornada Experimental Range is in the Chihuahua desert of the southwestern U.S.A. Observation metrics varied among these four datasets due to different protocols, so we converted all metrics to binary "yes" and "no" observations for each phenophase (see supplement for details). As with the NPN data, we inferred the date for each phenophase as the midpoint between the first "yes" observation and most recent "no" observation and only kept species x phenophases which had at least 30 total observations. 

\renewcommand{\arraystretch}{2}\tabcolsep=5pt
\begin{center}
    \begin{tabular}{ | l | l | l | l |}
    \hline
    Dataset Name & Habitat &  Phenological Event\newline (Num. Species) & Reference \\ \hline
    Harvard & N.E. Deciduous\newline Forest & Budburst (16)\newline Flowering (15) & \citep{okeefe2000} \\
    Jornada & Chihuahuan Desert & Flowering (2) & ... \\
    HJ Andrews \newline Experimental Forest & N.W. Wet Coniferous \newline Forest & Budburst (6)\newline Flowering (6) & ... \\
    Hubbard Brook & N.E. Deciduous \newline Forest & Budburst (3) & ... \\
    \hline
    \end{tabular}
\end{center}

\subsection*{Models}

Plant species all have unique phenological requirements, thus it is common to fit multiple models to find the one that best represents a specific species and phenophase \citep{chuine2013}. For each species and phenophase in each of the five datasets (NPN and four LTS datasets), we fit a range of phenology models ranging from a naive mean day of year estimate to more complex two phase forcing models (Table 2). The naive model uses the mean DOY from prior observations as the estimated DOY. The linear model uses a regression with the mean spring (Jan. 1 - March 31) temperature as the independent variable and DOY as the response variable. For the remaining models the general form is based on the idea that a phenological event will occur once sufficient thermal forcing units, $F^{*}$, accumulate from a particular start day of the year ($t_{1}$). The start day can either be estimated or fixed. For the growing degree day model (GDD) forcing units are the total degrees above the threshold $T$. The Fixed GDD model uses the same form but has fixed values for start day ($t_{1}$ = Jan 1) and temperature threshold ($T$ = 0C). The Alternating model has a variable number of required forcing units defined as a function of the total number of days below 0C since Jan. 1 ($NCD$). The Uniforc model is like the GDD model but with the forcing units transformed via a sigmoid function \citep{chuine2000}.

We also fit two models that attempt to capture spatial variation in phenological requirements. The first spatial model, M1, is an extension of the GDD model which adds a correction in the required forcing using the photoperiod ($L$) \citep{blumel2012}. The second, the Macroscale Species-specific Budburst model (MSB), uses the mean spring temperature as a linear correction on the total forcing required in the Alternating model \citep{jeong2013}. Since there is little to no spatial variation in the LTS datasets, the two spatial models were only fit to data from the NPN. The resulting parameters, estimates, and errors for the NPN derived M1 and MSB models were compared to their non-spatial analogs (the GDD and Alternating models, respectively) for each species and phenophase in the LTS data.  

\begin{center}
{\def\arraystretch{2}\tabcolsep=5pt
    \begin{tabular}{ | l | c | c | p{1.3cm} | l |}
    \hline
    Name & DOY Estimator & Forcing Equations & Total\newline Parameters & Reference \\ \hline
    Naive & \( \overline{DOY} \) & - & 1 & - \\
    Fixed GDD &$\sum_{t=0}^{DOY}R_{f}(T_{i})\geq F^{*} $  & $R_{f}(T_{i}) = min(T_{i}, 0)$ & 1 & - \\
    Linear & \( DOY = \beta_{1} + \beta_{2}T_{mean} \) & - & 2 & - \\
    GDD & $\sum_{t=t_{1}}^{DOY}R_{f}(T_{i})\geq F^{*} $ & $ R_{f}(T_{i}) = max(T_{i} - T^{*}, 0) $  & 3 & - \\
    M1 & $\sum_{t=t_{1}}^{DOY}R_{f}(T_{i})\geq (\frac{L_{i}}{24})^{k} F^{*} $ & $ R_{f}(T_{i}) = max(T_{i}-T^{*}, 5) $  & 4 & \citep{blumel2012} \\
    Alternating & $\sum_{t=0}^{DOY}R_{f}(T_{i})\geq a + be^{cNCD(t)} $ & $R_{f}(T_{i}) = max(T_{i}-5, 0) $ & 3 & \citep{cannell1983} \\
    MSB & $\sum_{t=0}^{DOY}R_{f}(T_{i})\geq a + be^{cNCD_{i}} +dT_{mean} $ & $R_{f}(T_{i}) = max(T_{i}-5, 0) $ & 4 & \citep{jeong2013} \\
    Uniforc &  $\sum_{t=t_{1}}^{DOY}R_{f}(T_{i})\geq F^{*} $ & $ R_{f}(T_{i}) = \frac{1}{1 + e^{b(T_{i}-c)}} $ & 4 & \citep{chuine2000} \\

    \hline
    \end{tabular}
    }
\end{center}

All models were parameterized using differential evolution to minimize the root mean square error (RMSE) of the estimated day of year of the phenological event. Differential evolution is a global optimization algorithm which uses a population of randomly initialized models to find the set of parameters that minimize the RMSE \citep{storn1997}. Confidence intervals for parameters were obtained by bootstrapping, where individual models were re-fit 250 times using a random sample, with replacement, of the data. A random 20\% of all data was held out from model fitting for model evaluation. Predictions were made by taking the mean DOY from the 250 bootstrapped models. 

\subsection*{Analysis}

As described above, two sets of models were produced for each species and phenophase: one set of models parameterized using only NPN data, and one set parameterized using only LTS data (with the exception of the M1 and MSB models, see above). To compare the inferences about process made by the two datasets we compared the distribution for each parameter in each species x phenophase model between LTS and NPN using a Mann-Whitney test (since the majority of parameters having non-normal distributions). Using the mean value of each bootstrapped parameter we also calculated the coefficient of determination ($R^2$) between LTS and NPN derived models among the 39 species-phenophases. In the three cases where the same species x phenophase combination occurred in two LTS sites, the two instances were compared separately to the NPN data.

Models with different parameter values, and even entirely different model structures, can produce similar estimates for the date of phenological events \citep{basler2016}. Therefore, to compare the predictions and potential forecasts for models fit to the different datasets we compared the estimated DOY predicted by the LTS and NPN derived models. We calculated the coefficient of determination ($R^2$) between LTS and NPN derived estimates for estimates made at the four LTS sites, and across all NPN sites, for each of the 6 models.   

We also directly evaluated model performance using four combinations of models and observed data: A) LTS derived models predicting LTS observations, B) NPN derived models predicting LTS observations, C) LTS derived models predicting NPN observations, and D) NPN derived models predicting NPN observations. Within each of these scenarios we calculated the RMSE of the held out observations for each species, phenophase, and model type. Using the RMSE values we calculated two difference metrics to compare the performance of LTS and NPN derived models on different data types. The first metric focuses on local scale prediction by comparing the fits of LTS and NPN derived models on LTS observations: $RMSE_{A} - RMSE_{B}$. The second metric focuses on large scale prediction by comparing the fits of LTS and NPN derived models on the NPN data: $RMSE_{C} - RMSE_{D}$. Negative values indicate LTS derived models perform better while positive values indicate the NPN derived model performed better. In the three cases where the same species x phenophase combination occurred in two LTS sites, the LTS-LTS comparison (scenario A) was made within each site, not across sites, to focus on local scale prediction when LTS data is available. Absolute RMSE values are provided in the supplement (Fig. S1-S3).


\begin{figure}[]
	\centering
		\includegraphics[width=1\textwidth]{fig_1_param_comparison.png}
	\caption{Comparisons of parameter estimates between NPN and LTS derived models. Each point represents a parameter value for a specific species and phenophase, and is the mean value from 250 bootstrapped models. The black line is the 1:1 line. The $R^2$ is the coefficient of determination, which can be negative if the relationship between the two parameter sets is worse than no relationship but with the same mean values.}
\end{figure}


\section*{Results}

The best matches between parameter estimates based on NPN and LTS data were the Fixed GDD model ($R^2$ = 0.49) and the Linear model ($R^2$ = 0.39 for $\beta_{1}$ and -0.05 for $\beta_{2}$). The parameters for all other models had $R^2$ values < 0 indicating that the relationship was worse than no relationship between the parameters but with matching mean parameter values across the two sets of models (Fig. 1). The Naive model showed a distinct late bias in mean DOY estimates for phenological events, likely resulting from the LTS datasets being mostly in the northern United States. The one major outlier for the Fixed GDD model, \textit{Larrea tridentata}, has phenology largely driven by precipitation, which is not considered in the Fixed GDD model \citep{beatley1974}. While the Fixed GDD and Linear models showed reasonable correspondence between parameter estimates, all parameters for individual species x phenophase combinations were statistically different between NPN and LTS derived models according to the Mann-Whitney U test (p < 0.001).

\begin{figure}
	\centering
		\includegraphics[width=1\textwidth]{fig_2_estimate_compare.png}
	\caption{Comparison of predicted day of year (DOY) of all phenological events between NPN and LTS derived models. Top panels show comparisons at LTS sites and bottom panels show comparisons at NPN sites. Each point is an estimate for a single held out observation. Colors indicate observations for a single species x phenophase combination.}
\end{figure}

When comparing estimates of phenological events between the two sets of models, many NPN and LTS models produced similar estimates (Fig. 2). The Fixed GDD model had the highest correlation between the two models sets at NPN sites ($R^2 = 0.82$), while the GDD, M1, and Uniforc models had the highest correlation at LTS sites ($R^2 = 0.54$). Comparing models with spatial corrections to the non-spatial alternatives, the MSB (an extension of the alternating model with a spatial correction based on mean spring temperature, see Table 2 and Methods) improved the correlation between the two datasets over the Alternating model. The MSB model improved the $R^2$ from 0.38 to 0.45 at LTS sites, and from -0.2 to -0.13 at NPN sites. The M1 model (an extension of the GDD model with a spatial correction based on daylength) did not improve the correlation between datasets over the GDD model. 

When comparing the prediction accuracy on held out data NPN derived models make more accurate predictions for held out NPN observations, and LTS derived models perform better on held out LTS observations (Fig. 3). The Naive and Linear models had the largest differences between the two model sets, while the Fixed GDD model had relatively similar errors when evaluated on both NPN and LTS held out observations. Though the Fixed GDD model had the highest agreement in accuracy between NPN and LTS derived models, it was not the best performing model overall. The GDD and Uniforc models commonly made the best predictions, having the lowest RMSE in 22\% and 40\% of cases among NPN derived models, and 42\% and 32\% of cases among LTS derived models, respectively (Fig. S1 \& S2).

\begin{figure}
	\centering
		\includegraphics[width=1\textwidth]{rmse_metrics_density_plot.png}
	\caption{Differences in prediction error between NPN and LTS derived models. Density plots for comparisons of predictions on LTS data (top row) and NPN data (bottom row). Each plot represents the difference between the RMSE for LTS derived model and the NPN derived model, meaning that values less than zero indicate more accurate prediction by LTS derived models and values greater than zero indicate more accurate prediction by NPN derived models. Differences are calculated pairwise for the 39 species/phenophase comparisons.}
\end{figure}


\section*{Discussion}

Data for building phenology models typically falls into two categories: intensive long-term data with long time-series at a small number of locations (e.g., the LTS data in this study) and large scale data with less intensive data at hundreds of locations (e.g., the NPN data). This data scenario, a small amount of intensive data and a large amount of less intensive data, is common in many areas of science, and results in the need to understand how to choose between, or combine, data sources. We explored this issue for phenology modeling at local and continental scales for making predictions and inferring process from models. For inference, we found that models based on different data sources resulted in different parameter estimates for all but the simplest models. For prediction we found that models fit to different data sources tended to make similar predictions, but that models better predicted out of sample data from the data type they were fit to. As a result the best choice of both data and models depends on the desired research goals. Understanding and making predictions for the phenology of a single location is best served by intensive local scale data, if it is available, but large scale datasets work better for extrapolating phenology predictions across a species range. These results are consistent with other research showing that phenology model performance decreases when transferring single site models to other locations \citep{garcia-mozo2008, xu2013, basler2016} and with the call for models that better incorporate spatial variation in phenology requirements \citep{richardson2013, chuine2017}.

In this study, parameter estimates differed widely within the same phenology model when fit to the two different types of data, except for the simplest process oriented model: the Fixed GDD (Fig. 1). These differences may be caused by a variety of factors that have different implications for interpreting process oriented models and their parameters. First, the differences could result from limitations in the sampling of the NPN dataset, leading to less accurate parameter estimates. If this is the case it would suggest using local scale data when it is available for making inferences about plant physiology and focusing on the Fixed GDD model when large scale data is all that is available. Second, spatial variation in phenology requirements could drive these differences, because large scale data integrates over that spatial variation, while local scale data only estimates the phenological requirements for a specific site. In this case large scale would provide a better estimate of the general phenological requirements of a species, but local scale data would provide a more accurate understanding for a single site. The best solution to this issue would be the development of models that accurately incorporate spatial variation. Finally, these differences could result from issues with model identifiability, where different parameter values yield nearly identical fits to the data, which can result in fits to different datasets varying widely even if the underlying processes generating the data are the same.

Information about which of these issues may be causing the differences between datasets can be explored using our analyses. Despite the substantial differences in parameter estimates the LTS and NPN derived models produced similar estimates for phenological events in most cases (Fig. 2). This greater correspondence between predictions than parameters suggests that more complex models may have identifiability issues. For example, two GDD models with parameters of $t_{1}$=1, $F$=10, $T*$=0 and $t_{1}$=5, $F$=5, $T*$=0 produce nearly identical results in many scenarios. This possibility is supported by the fact that the the highest correlation between parameter estimates is seen in a models with only 1 or 2 parameters. In addition, the bootstrap results for more complex models suggest a high degree of variability in parameter estimates and potentially multiple local optima in fits to both NPN and LTS data (Supplementary Material). Finally, parameter estimates of more complex models are also not consistent among models for the same species when comparing multiple LTS datasets (Supplementary Material). These results are consistent with research showing that models estimating endodormancy break from budbreak time-series failed to accurately infer the internal phenology described in the models \citep{chuine2016}. \cite{basler2016} suggests that the key component in phenology models is the thermal forcing, with additional parameters being sensitive to over fitting. Here, our simplest model, the Fixed GDD model which uses only a warming component, had the highest correlation among parameters between LTS and NPN datasets. In combination with this previous research, our results warrant caution in interpreting the parameter estimates from complex phenology models regardless of the data source used for fitting the models.

While complex phenology models appear to have identifiability issues, there is also evidence that they capture useful information beyond the Fixed GDD model based on their ability to make out-of-sample predictions. Based on the RMSE, the GDD and Uniforc models produce the best out-of-sample predictions for the majority of species and phenophases at both large and local scales (Fig. S1). For local scale predictions This demonstrates that the more complex models are capturing additional information about phenology and that some of the differences between datasets result from differences in either the scales or the sampling of the data. Spatial variation in phenological requirements is known to exist in plants \citep{zhang2017}, and in combination with our results showing observed differences in parameter estimates between LTS sites (Supplementary Material) this suggests that variation in phenological requirements across the the range is likely important. However, the models that attempted to address this by incorporating spatial variation did not yield improvements over their base models in our analyses. Correspondence between parameter estimates (Fig. 1), estimates of phenological events (Fig. 2), and out of sample error rates (Fig. 3) for the MSB and M1 models were essentially the same as the Alternating and GDD models, respectively. This lack of improvement from incorporating spatial variation could be caused either by models not adequately capturing the process driving the spatial variation, the NPN dataset having biases from variation in sampling effort and/or spatial auto-correlation, or some combination of these factors. \cite{basler2016} used the M1 model to predict budburst on six species across Europe and found it was usually among the best models in terms of RMSE, albeit never by more than a single day. Their result was strengthened by having a 40 year timeseries across a large region. \cite{chuine2017} noted that incorporating the spatial variation in warming requirements as a primary issue in future phenology research. Large-scale phenology datasets, like NPN, will be key in addressing this and other phenological research needs.

In addition to providing qualitative information about the source of differences between LTS and NPN data, our analysis provides guidance on how best to use phenology data and models currently available to fill the need for forecasts that inform decision makers and provide feedback for researchers \citep{clark2001, dietze2018}. Our results suggest that GDD and Uniforc are good choices for large scale forecasting based on NPN data (sensu. Scenario D) and that XXX and XXX are good choices for local scale forecasting using LTS data (Scenario A). Other models show promise for forecasting under different scenarios. For example, if using data from a large spatial extent to make predictions at single sites (Scenario B) our results show that the Alternating model is the best option, as performance under this scenario is very similar to performance of Alternating models built from LTS data (Fig. 3). In the opposite scenario of making large-scale predictions using only data from a single site (sensu. Scenario C) the Fixed GDD model is likely the best option, as most LTS derived Fixed GDD models have a RMSE only 5 days greater, on average, than the corresponding NPN model (Fig. 4). 

In conclusion, our results suggest that both intensive local scale data and large scale citizen science efforts provide valuable information on plant phenology. While identifying the most effective data sources for different types and scales of analysis is a useful first step, the ultimate solution to working with diverse data types is to focus on integrating all types of data into analyses and forecasts \citep{hanks2018}. Datasets with long, regularly sampled, time series contain valuable information on inter annual variation, while large scale data captures information on numerous species and how phenology varies across the range  \citep{xu2013, olsson2014, basler2016, zhang2017}. Our results suggest that methods that can weight LTS data heavily in nearby regions and use large scale data to explicitly capture spatial variation in phenological requirements will help improve both our understanding of phenology and our ability to make predictions. Data integration efforts should also leverage data from remote sensing sources such as the PHENOCAM network, which has a large spatial extent as well as a daily temporal grain \citep{richardson2018}, and phenology information derived from satellite imagery. More complex data integration methods that use data from many sources to give the best estimate for forecasts \citep{ogle2015} and continuously update forecasts as new real time data becomes available \citep{luo2011, dietze2018}, provide the best opportunity for accurate inference about, and forecasting of, the timing of biological events.


\section*{Acknowledgments}

\bibliography{refs}

\setcounter{figure}{0}    
\section*{Supplement}
\begin{figure}
	\centering
		\includegraphics[width=1\textwidth]{supplement_best_npn_models.png}
	\caption{RMSE for specific species and phenophases of the NPN dataset. X marks the best performing models for the respective data type.}
\end{figure}

\begin{figure}
	\centering
		\includegraphics[width=1\textwidth]{supplement_best_lts_models.png}
	\caption{RMSE for specific species and phenophases of the LTS datasets. X marks the best performing models for the respective data type.}
\end{figure}

\begin{figure}
	\centering
		\includegraphics[width=1\textwidth]{supplement_scenario_absolute_rmse.png}
	\caption{RMSE of all species and phenophases of the four scenarios described in the text. These values are calculated using held out test data.}
\end{figure}

\begin{figure}
	\centering
		\includegraphics[width=1\textwidth]{fig_s3_site_map.png}
	\caption{Locations of National Phenology Network sites used (black points) and Long Term Study sites (labeled circles).}
\end{figure}

\begin{figure}
	\centering
		\includegraphics[width=1\textwidth]{hubbard_harvard_comparison.png}
	\caption{Distribution of model parameters for the three species common to the Hubbard Brook, Harvard, and NPN datasets. The phenophase is budburst for all three species. Vertical lines indicate either the mean (solid) or median (dashed) of the respective distribution.}
\end{figure}


\end{document}
